# Orchestrator 3 Stream Environment Configuration
# Copy this file to .env and fill in your values

# ═══════════════════════════════════════════════════════════
# DATABASE CONFIGURATION
# ═══════════════════════════════════════════════════════════

# PostgreSQL connection string
DATABASE_URL=postgresql://user:password@localhost:5432/orchestrator_db

# ═══════════════════════════════════════════════════════════
# API CONFIGURATION
# ═══════════════════════════════════════════════════════════

# Anthropic API key for Claude
ANTHROPIC_API_KEY=sk-ant-api03-...

# Default model for orchestrator
DEFAULT_MODEL=claude-3-5-sonnet-20241022

# ═══════════════════════════════════════════════════════════
# TOKEN MANAGEMENT CONFIGURATION
# ═══════════════════════════════════════════════════════════

# Enable token optimization features (true/false)
TOKEN_MANAGEMENT_ENABLED=true

# Maximum context window settings - FULL CAPACITY for effective orchestration
# Claude Sonnet 4.5 has 200k token context window
# These settings use 60% (120k) for context, leaving 80k for responses + overhead
# Message limit (200) is generous - token limit (120k) is the real constraint
MAX_CONTEXT_MESSAGES=200        # Generous limit (was 20)
MAX_CONTEXT_TOKENS=120000       # 60% of 200k window (was 25,000)

# ═══════════════════════════════════════════════════════════
# RATE LIMITING
# ═══════════════════════════════════════════════════════════

# Maximum tokens per minute (600k = 60% of 1M API limit)
RATE_LIMIT_TOKENS_PER_MINUTE=600000

# Threshold to start backing off (0.8 = 80% of limit)
RATE_LIMIT_BACKOFF_THRESHOLD=0.8

# ═══════════════════════════════════════════════════════════
# RESPONSE CACHING + PROMPT CACHING STRATEGY
# ═══════════════════════════════════════════════════════════

# Enable response caching (true/false)
RESPONSE_CACHE_ENABLED=true

# Maximum cache size in MB
RESPONSE_CACHE_MAX_SIZE=100

# Cache time-to-live in seconds (3600 = 1 hour)
# Longer TTL = better cache hit rate = massive cost savings
RESPONSE_CACHE_TTL_SECONDS=3600

# ═══════════════════════════════════════════════════════════
# PROMPT CACHING ECONOMICS (Anthropic's automatic caching)
# ═══════════════════════════════════════════════════════════
# Claude automatically caches static content (system prompts, conversation history)
#
# Pricing:
# - Cache write (5-min TTL): 1.25× base input ($3.75/1M tokens for Sonnet 4.5)
# - Cache hit: 0.1× base input ($0.30/1M tokens) = 90% SAVINGS!
#
# What gets auto-cached by Claude SDK:
# 1. System prompt (orchestrator_agent_system_prompt.md + CLAUDE.md) ~15-20k tokens
# 2. Conversation history (managed by MAX_CONTEXT_TOKENS) up to 120k tokens
#
# Expected savings with continuous orchestrator usage:
# - First request: Pays 1.25× to write ~120k tokens to cache ($0.45)
# - Next 9 requests within 5 min: Pay 0.1× for cache hits ($0.036 each = $0.32 total)
# - Total for 10 requests: $0.77 vs $3.60 without cache = 79% savings!
#
# Pro tip: Keep orchestrator running continuously to maximize cache hits
# ═══════════════════════════════════════════════════════════

# ═══════════════════════════════════════════════════════════
# COST TRACKING
# ═══════════════════════════════════════════════════════════

# Cost alert threshold in USD
COST_ALERT_THRESHOLD_USD=10.0

# Cost per million tokens (input) - Claude 3.5 Sonnet pricing
COST_PER_M_TOKENS_INPUT=3.0

# Cost per million tokens (output) - Claude 3.5 Sonnet pricing
COST_PER_M_TOKENS_OUTPUT=15.0

# ═══════════════════════════════════════════════════════════
# CONVERSATION SUMMARIZATION
# ═══════════════════════════════════════════════════════════

# Number of messages before triggering summarization
SUMMARIZATION_THRESHOLD_MESSAGES=20

# Target word count for summaries
SUMMARY_LENGTH_WORDS=200

# Model to use for summarization (Haiku recommended for cost)
SUMMARY_MODEL=claude-3-haiku-20240307

# ═══════════════════════════════════════════════════════════
# LOGGING AND MONITORING
# ═══════════════════════════════════════════════════════════

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable detailed token usage logging
LOG_TOKEN_USAGE=true

# Enable cost tracking logs
LOG_COST_TRACKING=true

# ═══════════════════════════════════════════════════════════
# PERFORMANCE TUNING
# ═══════════════════════════════════════════════════════════

# Default chat history limit for loading
DEFAULT_CHAT_HISTORY_LIMIT=50

# Number of recent messages to keep full content
RECENT_MESSAGES_FULL_CONTENT=10

# Number of older message summaries to include
OLDER_MESSAGES_SUMMARY_COUNT=5

# ═══════════════════════════════════════════════════════════
# SERVER CONFIGURATION
# ═══════════════════════════════════════════════════════════

# Backend server port
BACKEND_PORT=9403

# Frontend server port
FRONTEND_PORT=9503

# WebSocket ping interval in seconds
WS_PING_INTERVAL=30

# ═══════════════════════════════════════════════════════════
# FEATURE FLAGS
# ═══════════════════════════════════════════════════════════

# Enable experimental features
ENABLE_EXPERIMENTAL=false

# Enable debug mode
DEBUG_MODE=false

# ═══════════════════════════════════════════════════════════
# NOTES
# ═══════════════════════════════════════════════════════════

# Token Optimization Settings Guide:
#
# 1. MAX_CONTEXT_MESSAGES: Start with 50, reduce if hitting token limits
# 2. MAX_CONTEXT_TOKENS: Start with 50k (25% of 200k limit), adjust based on needs
# 3. RATE_LIMIT_TOKENS_PER_MINUTE: Start at 400k (40% of limit), increase if stable
# 4. CACHE_TTL_SECONDS: Longer = better hit rate, but staler responses
# 5. COST_ALERT_THRESHOLD_USD: Set based on your budget comfort level
#
# Performance Impact:
# - Context trimming: Reduces input tokens by 40-50%
# - Response caching: Saves 10-20% on repeated queries
# - Conversation summarization: Reduces tokens by 20-30% in long chats
# - Total expected savings: 50-70% reduction in API costs
#
# Monitoring:
# - Check /api/metrics/tokens for real-time usage
# - Check /api/metrics/cache for cache performance
# - Check /api/metrics/costs for spending tracking
# - Use /api/cache/clear to manually reset cache if needed