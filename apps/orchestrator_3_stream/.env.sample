# Orchestrator 3 Stream Environment Configuration
# Copy this file to .env and fill in your values

# ═══════════════════════════════════════════════════════════
# DATABASE CONFIGURATION
# ═══════════════════════════════════════════════════════════

# PostgreSQL connection string
DATABASE_URL=postgresql://user:password@localhost:5432/orchestrator_db

# ═══════════════════════════════════════════════════════════
# API CONFIGURATION
# ═══════════════════════════════════════════════════════════

# Anthropic API key for Claude
ANTHROPIC_API_KEY=sk-ant-api03-...

# Default model for orchestrator
DEFAULT_MODEL=claude-3-5-sonnet-20241022

# ═══════════════════════════════════════════════════════════
# TOKEN MANAGEMENT CONFIGURATION
# ═══════════════════════════════════════════════════════════

# Enable token optimization features (true/false)
TOKEN_MANAGEMENT_ENABLED=true

# Maximum context window settings
# PRIORITY 1: AGGRESSIVE SETTINGS TO FIX 90% RATE LIMITING
# Number of messages to keep in context (reduced from 50)
MAX_CONTEXT_MESSAGES=20

# Maximum tokens allowed in context window (reduced from 50000)
MAX_CONTEXT_TOKENS=25000

# ═══════════════════════════════════════════════════════════
# RATE LIMITING
# ═══════════════════════════════════════════════════════════

# Maximum tokens per minute (400k = 40% of 1M limit)
RATE_LIMIT_TOKENS_PER_MINUTE=400000

# Threshold to start backing off (0.8 = 80% of limit)
RATE_LIMIT_BACKOFF_THRESHOLD=0.8

# ═══════════════════════════════════════════════════════════
# RESPONSE CACHING
# ═══════════════════════════════════════════════════════════

# Enable response caching (true/false)
RESPONSE_CACHE_ENABLED=true

# Maximum cache size in MB
RESPONSE_CACHE_MAX_SIZE=100

# Cache time-to-live in seconds (3600 = 1 hour)
RESPONSE_CACHE_TTL_SECONDS=3600

# ═══════════════════════════════════════════════════════════
# COST TRACKING
# ═══════════════════════════════════════════════════════════

# Cost alert threshold in USD
COST_ALERT_THRESHOLD_USD=10.0

# Cost per million tokens (input) - Claude 3.5 Sonnet pricing
COST_PER_M_TOKENS_INPUT=3.0

# Cost per million tokens (output) - Claude 3.5 Sonnet pricing
COST_PER_M_TOKENS_OUTPUT=15.0

# ═══════════════════════════════════════════════════════════
# CONVERSATION SUMMARIZATION
# ═══════════════════════════════════════════════════════════

# Number of messages before triggering summarization
SUMMARIZATION_THRESHOLD_MESSAGES=20

# Target word count for summaries
SUMMARY_LENGTH_WORDS=200

# Model to use for summarization (Haiku recommended for cost)
SUMMARY_MODEL=claude-3-haiku-20240307

# ═══════════════════════════════════════════════════════════
# LOGGING AND MONITORING
# ═══════════════════════════════════════════════════════════

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable detailed token usage logging
LOG_TOKEN_USAGE=true

# Enable cost tracking logs
LOG_COST_TRACKING=true

# ═══════════════════════════════════════════════════════════
# PERFORMANCE TUNING
# ═══════════════════════════════════════════════════════════

# Default chat history limit for loading
DEFAULT_CHAT_HISTORY_LIMIT=50

# Number of recent messages to keep full content
RECENT_MESSAGES_FULL_CONTENT=10

# Number of older message summaries to include
OLDER_MESSAGES_SUMMARY_COUNT=5

# ═══════════════════════════════════════════════════════════
# SERVER CONFIGURATION
# ═══════════════════════════════════════════════════════════

# Backend server port
BACKEND_PORT=9403

# Frontend server port
FRONTEND_PORT=9503

# WebSocket ping interval in seconds
WS_PING_INTERVAL=30

# ═══════════════════════════════════════════════════════════
# FEATURE FLAGS
# ═══════════════════════════════════════════════════════════

# Enable experimental features
ENABLE_EXPERIMENTAL=false

# Enable debug mode
DEBUG_MODE=false

# ═══════════════════════════════════════════════════════════
# NOTES
# ═══════════════════════════════════════════════════════════

# Token Optimization Settings Guide:
#
# 1. MAX_CONTEXT_MESSAGES: Start with 50, reduce if hitting token limits
# 2. MAX_CONTEXT_TOKENS: Start with 50k (25% of 200k limit), adjust based on needs
# 3. RATE_LIMIT_TOKENS_PER_MINUTE: Start at 400k (40% of limit), increase if stable
# 4. CACHE_TTL_SECONDS: Longer = better hit rate, but staler responses
# 5. COST_ALERT_THRESHOLD_USD: Set based on your budget comfort level
#
# Performance Impact:
# - Context trimming: Reduces input tokens by 40-50%
# - Response caching: Saves 10-20% on repeated queries
# - Conversation summarization: Reduces tokens by 20-30% in long chats
# - Total expected savings: 50-70% reduction in API costs
#
# Monitoring:
# - Check /api/metrics/tokens for real-time usage
# - Check /api/metrics/cache for cache performance
# - Check /api/metrics/costs for spending tracking
# - Use /api/cache/clear to manually reset cache if needed