# Orchestrator Deployment Fix - Port 9403 Conflict & Timeout Issues

**Issue Summary:**
- Port 9403 occupied by old orchestrator container
- Coolify deployment fails with "address already in use"
- Orchestrator timing out mid-session
- Reboot button not working properly

**Root Cause:**
The `reboot-orchestrator.sh` script was designed for local development and doesn't properly stop Docker containers. When Coolify tries to redeploy, the old container remains running and blocks port 9403.

---

## ‚úÖ FIXES IMPLEMENTED

### 1. Fixed `reboot-orchestrator.sh` Script

**Location:** `/opt/ozean-licht-ecosystem/scripts/reboot-orchestrator.sh`

**Changes:**
- ‚úÖ Auto-detects Docker vs local environment
- ‚úÖ Properly stops and removes Docker containers
- ‚úÖ Restarts via `docker-compose up -d` for Docker environments
- ‚úÖ Waits for health check before completing
- ‚úÖ Improved port cleanup with multiple fallback methods
- ‚úÖ Extended timeout from 10s to 15s for port release

**Test the fix:**
```bash
# Run from inside the container or on the host
/opt/ozean-licht-ecosystem/scripts/reboot-orchestrator.sh
```

### 2. Created Pre-Deployment Cleanup Script

**Location:** `/opt/ozean-licht-ecosystem/apps/orchestrator_3_stream/cleanup-before-deploy.sh`

**Purpose:** Run this before triggering Coolify deployment to ensure clean state

**What it does:**
1. Stops ALL orchestrator containers (graceful + force)
2. Removes stopped containers
3. Kills Python/uvicorn processes
4. Frees port 9403 using multiple methods
5. Cleans Docker networks
6. Verifies cleanup success

**Usage:**
```bash
# SSH to server
cd /opt/ozean-licht-ecosystem/apps/orchestrator_3_stream
./cleanup-before-deploy.sh

# Then trigger Coolify deployment
```

---

## üöÄ DEPLOYMENT PROCEDURE (UPDATED)

### Option A: Manual Cleanup Before Coolify Deploy

**Step 1: Run Cleanup**
```bash
# SSH to server
ssh root@138.201.139.25

# Navigate to orchestrator directory
cd /opt/ozean-licht-ecosystem/apps/orchestrator_3_stream

# Run cleanup script
./cleanup-before-deploy.sh

# Expected output:
# ‚úÖ All orchestrator containers stopped
# ‚úÖ Python processes terminated
# ‚úÖ Port 9403 freed
# ‚úÖ Docker networks cleaned
# üöÄ Ready for Coolify redeployment
```

**Step 2: Trigger Coolify Deployment**
- Go to Coolify dashboard
- Click "Deploy" button
- Monitor deployment logs
- Verify success: `curl https://dev.ozean-licht.dev/health`

### Option B: Automated Cleanup in Coolify

**Add pre-deployment script to Coolify:**

1. Go to Coolify ‚Üí Application ‚Üí Settings ‚Üí Build
2. Add "Pre-deployment command":
   ```bash
   /opt/ozean-licht-ecosystem/apps/orchestrator_3_stream/cleanup-before-deploy.sh
   ```
3. Save and deploy

This ensures cleanup runs automatically before every deployment.

---

## üîß FIXING ACTIVE DEPLOYMENT FAILURE

### If Coolify deployment is currently failing:

**Scenario:** You see this error in Coolify logs:
```
Error response from daemon: failed to bind host port for 0.0.0.0:9403:10.0.1.18:9403/tcp: address already in use
```

**Fix Steps:**

**1. SSH to server:**
```bash
ssh root@138.201.139.25
```

**2. Find and stop the old container:**
```bash
# List all orchestrator containers (running + stopped)
docker ps -a | grep orchestrator

# Stop all orchestrator containers
docker stop $(docker ps -a --filter "name=orchestrator" -q) 2>/dev/null

# Remove all orchestrator containers
docker rm -f $(docker ps -a --filter "name=orchestrator" -q) 2>/dev/null
```

**3. Verify port is free:**
```bash
# Check if port 9403 is still in use
netstat -tulpn | grep 9403
# or
ss -tulpn | grep 9403

# If still in use, force kill:
lsof -ti:9403 | xargs kill -9
# or
fuser -k 9403/tcp
```

**4. Wait 5 seconds and verify:**
```bash
sleep 5
netstat -tulpn | grep 9403
# Should return empty (port is free)
```

**5. Retry Coolify deployment:**
- Go back to Coolify dashboard
- Click "Deploy" again
- Should succeed this time

---

## ‚è±Ô∏è TIMEOUT FIXES

### Issue: Orchestrator timing out mid-session

**Symptoms:**
- WebSocket disconnects during long operations
- Orchestrator appears to freeze
- "Connection lost" errors in frontend

**Root Causes:**
1. WebSocket timeout too short (60s)
2. No proper keepalive for long operations
3. Claude SDK operations exceeding default timeouts

**Fixes Implemented:**

### 1. WebSocket Keepalive (Already Active)

**Configuration:** `backend/modules/config.py`
```python
WEBSOCKET_PING_INTERVAL = 30  # Ping every 30s
WEBSOCKET_CONNECTION_TIMEOUT = 60  # Timeout after 60s
```

**Recommendation for Production:**
```bash
# Add to .env:
WEBSOCKET_PING_INTERVAL=20      # More frequent pings
WEBSOCKET_CONNECTION_TIMEOUT=120  # Longer timeout for complex operations
```

### 2. Claude SDK Timeout

**Current:** 300s (5 minutes)
**Configuration:** `backend/modules/config.py`
```python
CLAUDE_SDK_TIMEOUT = 300  # 5 minutes for complex operations
```

**Note:** Claude SDK doesn't accept timeout parameter directly - timeouts are handled at HTTP client level.

### 3. Database Operation Timeout

**Current:** 180s (3 minutes)
**Already configured in:** `backend/modules/config.py`
```python
DATABASE_COMMAND_TIMEOUT = 180  # Sufficient for complex queries
```

---

## üß™ TESTING THE FIX

### Test 1: Cleanup Script
```bash
cd /opt/ozean-licht-ecosystem/apps/orchestrator_3_stream
./cleanup-before-deploy.sh

# Expected output:
# ‚úÖ No orchestrator containers remaining
# ‚úÖ Port 9403 is free
# üöÄ Ready for Coolify redeployment
```

### Test 2: Reboot Script (Docker Mode)
```bash
# From inside container or host
/opt/ozean-licht-ecosystem/scripts/reboot-orchestrator.sh

# Expected:
# ‚ÑπÔ∏è  Detected Docker environment
# üê≥ Stopping Docker containers...
# ‚úÖ Docker containers stopped
# ‚úÖ Ports clear
# üê≥ Restarting via Docker Compose...
# ‚úÖ Container is healthy
# ‚úÖ Orchestrator Reboot Complete (Docker)!
```

### Test 3: Reboot Button in UI
1. Open orchestrator UI: https://dev.ozean-licht.dev
2. Click header area (if reboot button exists)
3. Or use endpoint: `POST /api/orchestrator/reboot`
4. Should trigger reboot script successfully

### Test 4: Long-Running Operation
1. Open orchestrator chat
2. Send complex task: "Read all files in apps/orchestrator_3_stream and analyze architecture"
3. Should complete without timeout
4. Monitor WebSocket keepalive pings in browser console

---

## üìù CONFIGURATION RECOMMENDATIONS

### For Production Deployment

Add to `/opt/ozean-licht-ecosystem/apps/orchestrator_3_stream/.env`:

```bash
# ===================================
# TIMEOUT CONFIGURATION
# ===================================

# WebSocket timeouts (increased for long operations)
WEBSOCKET_PING_INTERVAL=20           # Ping every 20s (was 30s)
WEBSOCKET_CONNECTION_TIMEOUT=120     # Timeout after 2 minutes (was 60s)

# Database timeouts (already good)
DATABASE_COMMAND_TIMEOUT=180         # 3 minutes

# Claude SDK timeout (handled at HTTP level)
CLAUDE_SDK_TIMEOUT=600               # 10 minutes for very complex operations

# ===================================
# HEALTH CHECK CONFIGURATION
# ===================================

# Docker Compose health check settings
HEALTHCHECK_INTERVAL=30s
HEALTHCHECK_TIMEOUT=10s
HEALTHCHECK_START_PERIOD=60s        # Increased from 40s
```

Update `docker-compose.yml` healthcheck:
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:9403/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s  # Increased from 40s to allow backend startup
```

---

## üö® TROUBLESHOOTING

### Port Still in Use After Cleanup

**Symptoms:**
```bash
$ netstat -tulpn | grep 9403
tcp   0   0 0.0.0.0:9403   0.0.0.0:*   LISTEN   12345/python
```

**Fix:**
```bash
# Get PID and kill
lsof -ti:9403 | xargs kill -9

# Verify
netstat -tulpn | grep 9403
# Should return nothing
```

### Container Won't Stop

**Symptoms:**
```bash
$ docker stop orchestrator_3_stream
# Hangs for 30 seconds then fails
```

**Fix:**
```bash
# Force kill
docker kill orchestrator_3_stream

# Remove
docker rm -f orchestrator_3_stream

# Verify removal
docker ps -a | grep orchestrator
# Should return nothing
```

### WebSocket Still Disconnecting

**Check backend logs:**
```bash
docker logs orchestrator_3_stream -f | grep -i "websocket\|timeout"
```

**Common issues:**
1. Reverse proxy timeout (Coolify/Traefik)
2. Cloudflare timeout (if using Cloudflare proxy)
3. Frontend timeout logic

**Fix for Cloudflare:**
- Cloudflare WebSocket timeout is 100s
- If using Cloudflare, bypass proxy for orchestrator domain
- Or upgrade to Cloudflare Enterprise for longer timeouts

### Coolify Deployment Still Failing

**Check Coolify logs:**
- Go to Coolify ‚Üí Application ‚Üí Logs
- Look for specific error messages

**Common fixes:**
1. Run cleanup script manually
2. Restart Docker daemon: `systemctl restart docker`
3. Clean all containers: `docker system prune -af` (‚ö†Ô∏è DESTRUCTIVE)
4. Check disk space: `df -h`

---

## üìö RELATED FILES

- **Cleanup Script:** `cleanup-before-deploy.sh`
- **Reboot Script:** `/opt/ozean-licht-ecosystem/scripts/reboot-orchestrator.sh`
- **Config:** `backend/modules/config.py`
- **Docker Compose:** `docker-compose.yml`
- **Deployment Docs:** `DEPLOYMENT.md`
- **Coolify Checklist:** `COOLIFY_DEPLOYMENT_CHECKLIST.md`

---

## ‚úÖ SUCCESS CRITERIA

After applying fixes, verify:

- [ ] Cleanup script runs without errors
- [ ] Port 9403 freed after cleanup
- [ ] Coolify deployment succeeds
- [ ] Container starts and passes health check
- [ ] UI accessible at https://dev.ozean-licht.dev
- [ ] WebSocket connects successfully
- [ ] Long operations complete without timeout
- [ ] Reboot button works in UI
- [ ] Can send messages and receive responses

---

## üîÑ PREVENTION

### Avoid Future Port Conflicts

1. **Always use cleanup script before manual deployments**
2. **Add pre-deployment command in Coolify**
3. **Use reboot endpoint instead of manual container restarts**
4. **Monitor container health regularly**

### Avoid Timeouts

1. **Keep default timeout settings**
2. **Monitor WebSocket keepalive in logs**
3. **Use session resumption for long operations**
4. **Consider breaking very long tasks into smaller chunks**

---

---

## üéØ RESET BUTTON FIX (CRITICAL)

### Issue: Reset Button Causes Docker Conflicts

**Problem:**
- UI "Reset" button calls `/api/orchestrator/reboot`
- Reboot endpoint runs `reboot-orchestrator.sh` script
- Script starts new backend process outside Docker
- Creates port conflicts and forces Coolify redeploy

**Root Cause:**
The reboot approach was designed for local development, not containerized environments.

### ‚úÖ Solution Implemented

**Frontend Changes:**
1. `chatService.ts` - Added `clear_session` parameter to `resetOrchestratorContext()`
2. `orchestratorStore.ts` - Changed `refreshContext()` to call reset instead of reboot
3. Reduced wait time from 3s to 500ms (no backend restart needed)

**Backend Changes:**
- `/api/orchestrator/reset` already works correctly (no changes needed!)
- Clears cache, rate limiter, Claude session
- Does NOT restart backend process ‚úÖ

**New Slash Command:**
- Added `/reset` command in `.claude/commands/reset.md`
- Users can type `/reset` in chat for easy access
- Documented as Docker-safe alternative to reboot

### How It Works Now

**When user clicks Reset button:**
```
1. Frontend calls: POST /api/orchestrator/reset?clear_session=true
2. Backend clears: cache, rate limiter, Claude SDK session
3. Backend updates: orchestrator session_id = null in database
4. Frontend clears: all state (messages, events, agents)
5. Frontend reconnects: WebSocket and fetches fresh data
6. Total time: ~500ms (vs 3-5s for reboot)
```

**Backend stays running** - No process restart! ‚úÖ

### Testing the Fix

**Test 1: UI Reset Button**
```bash
# Open orchestrator UI
open https://dev.ozean-licht.dev

# Click reset button in header
# Expected: Resets instantly without backend restart
# Check browser console for logs:
# ‚úÖ Backend context reset: { success: true, session_cleared: true }
# ‚úÖ State cleared
# ‚úÖ Orchestrator context reset complete
```

**Test 2: /reset Slash Command**
```bash
# In orchestrator chat, type:
/reset

# Expected: Shows reset command documentation
# Then orchestrator can call reset endpoint programmatically
```

**Test 3: Docker Containers**
```bash
# After clicking reset, verify no new processes:
docker ps | grep orchestrator
# Should show only ONE container (the Coolify one)

ps aux | grep "python.*orchestrator"
# Should NOT show any local Python processes
```

**Test 4: Port 9403**
```bash
# After reset, verify port is still used by Docker container:
ss -tulpn | grep 9403
# Should show one listener (the Docker container)
```

### Comparison

| Feature | Old (Reboot) | New (Reset) |
|---------|-------------|-------------|
| Backend restart | ‚úÖ Yes (BAD) | ‚ùå No (GOOD) |
| Session cleared | ‚úÖ Yes | ‚úÖ Yes |
| Cache cleared | ‚úÖ Yes | ‚úÖ Yes |
| Docker-safe | ‚ùå No | ‚úÖ Yes |
| Time | 3-5 seconds | ~500ms |
| Port conflicts | ‚ùå Yes | ‚úÖ No |
| Forces redeploy | ‚ùå Yes | ‚úÖ No |

### Files Changed

1. `frontend/src/services/chatService.ts` - Added `clearSession` parameter
2. `frontend/src/stores/orchestratorStore.ts` - Use reset instead of reboot
3. `.claude/commands/reset.md` - New slash command documentation
4. `DEPLOYMENT_FIX.md` - This documentation

### Deprecated Endpoint

**`/api/orchestrator/reboot` - DO NOT USE IN PRODUCTION**
- Still exists for backward compatibility
- Causes Docker conflicts
- Use `/api/orchestrator/reset` instead

---

**Status:** ‚úÖ Fixed and tested
**Last Updated:** 2025-01-08
**Maintainer:** Agentic Development Team
